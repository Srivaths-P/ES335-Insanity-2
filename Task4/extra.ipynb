{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 3., 2., 1., 5., 2., 1., 3., 1.],\n",
       "        [2., 5., 2., 2., 1., 2., 4., 3., 4., 1.],\n",
       "        [5., 3., 5., 1., 1., 5., 4., 1., 3., 1.],\n",
       "        [4., 2., 5., 1., 3., 2., 4., 2., 3., 3.],\n",
       "        [3., 1., 3., 2., 2., 3., 5., 3., 4., 3.],\n",
       "        [4., 3., 5., 4., 3., 5., 1., 3., 1., 3.],\n",
       "        [1., 4., 5., 3., 3., 2., 2., 2., 2., 5.],\n",
       "        [5., 4., 4., 5., 3., 5., 2., 4., 3., 4.],\n",
       "        [1., 5., 1., 5., 3., 4., 4., 4., 2., 5.],\n",
       "        [4., 4., 3., 5., 5., 4., 2., 4., 2., 4.],\n",
       "        [5., 3., 4., 3., 1., 3., 1., 2., 1., 1.],\n",
       "        [4., 3., 5., 5., 5., 2., 3., 4., 5., 1.],\n",
       "        [4., 4., 5., 5., 3., 3., 4., 3., 2., 3.],\n",
       "        [1., 1., 4., 2., 5., 2., 1., 5., 1., 1.],\n",
       "        [3., 1., 3., 2., 2., 5., 3., 1., 3., 3.],\n",
       "        [5., 5., 4., 4., 4., 3., 3., 5., 3., 1.],\n",
       "        [4., 4., 2., 4., 1., 5., 1., 2., 3., 3.],\n",
       "        [5., 3., 5., 4., 1., 4., 4., 4., 4., 5.],\n",
       "        [1., 3., 4., 1., 5., 1., 3., 4., 2., 4.],\n",
       "        [4., 2., 5., 5., 4., 3., 1., 3., 4., 2.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "n_users, n_movies = 20, 10\n",
    "\n",
    "# A is a matrix of size (n_users, n_movies) randomly generated values between 1 and 5\n",
    "A = torch.randint(1, 6, (n_users, n_movies), dtype=torch.float)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50.4185)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "r = 3\n",
    "W = torch.randn(n_users, r, requires_grad=True, device=device)\n",
    "H = torch.randn(r, n_movies, requires_grad=True, device=device)\n",
    "\n",
    "A = A.to(device)\n",
    "\n",
    "# Compute the loss\n",
    "with torch.no_grad():\n",
    "    loss = torch.norm(torch.mm(W, H) - A)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.025517</td>\n",
       "      <td>-0.563092</td>\n",
       "      <td>-0.025753</td>\n",
       "      <td>-0.829404</td>\n",
       "      <td>0.513992</td>\n",
       "      <td>-0.248029</td>\n",
       "      <td>-0.091841</td>\n",
       "      <td>-0.199761</td>\n",
       "      <td>0.472571</td>\n",
       "      <td>-0.094532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.458479</td>\n",
       "      <td>0.149226</td>\n",
       "      <td>-1.662141</td>\n",
       "      <td>-3.959543</td>\n",
       "      <td>3.646095</td>\n",
       "      <td>0.308745</td>\n",
       "      <td>-3.372631</td>\n",
       "      <td>-3.370413</td>\n",
       "      <td>0.984193</td>\n",
       "      <td>1.541942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.421752</td>\n",
       "      <td>-0.075710</td>\n",
       "      <td>0.267425</td>\n",
       "      <td>1.090720</td>\n",
       "      <td>-0.775943</td>\n",
       "      <td>0.673958</td>\n",
       "      <td>-0.334709</td>\n",
       "      <td>-0.214609</td>\n",
       "      <td>-0.921345</td>\n",
       "      <td>1.143325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.993805</td>\n",
       "      <td>-0.958298</td>\n",
       "      <td>0.312328</td>\n",
       "      <td>-0.467862</td>\n",
       "      <td>0.044746</td>\n",
       "      <td>-0.400146</td>\n",
       "      <td>0.482238</td>\n",
       "      <td>0.317088</td>\n",
       "      <td>0.487932</td>\n",
       "      <td>-0.345960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.433204</td>\n",
       "      <td>0.878320</td>\n",
       "      <td>1.217203</td>\n",
       "      <td>4.024843</td>\n",
       "      <td>-3.373741</td>\n",
       "      <td>-0.092877</td>\n",
       "      <td>2.899760</td>\n",
       "      <td>3.032882</td>\n",
       "      <td>-1.187196</td>\n",
       "      <td>-1.501388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.025517 -0.563092 -0.025753 -0.829404  0.513992 -0.248029 -0.091841   \n",
       "1 -5.458479  0.149226 -1.662141 -3.959543  3.646095  0.308745 -3.372631   \n",
       "2 -0.421752 -0.075710  0.267425  1.090720 -0.775943  0.673958 -0.334709   \n",
       "3  0.993805 -0.958298  0.312328 -0.467862  0.044746 -0.400146  0.482238   \n",
       "4  4.433204  0.878320  1.217203  4.024843 -3.373741 -0.092877  2.899760   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.199761  0.472571 -0.094532  \n",
       "1 -3.370413  0.984193  1.541942  \n",
       "2 -0.214609 -0.921345  1.143325  \n",
       "3  0.317088  0.487932 -0.345960  \n",
       "4  3.032882 -1.187196 -1.501388  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(torch.mm(W, H).cpu().detach().numpy()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9\n",
       "0  2.0  1.0  3.0  2.0  1.0  5.0  2.0  1.0  3.0  1.0\n",
       "1  2.0  5.0  2.0  2.0  1.0  2.0  4.0  3.0  4.0  1.0\n",
       "2  5.0  3.0  5.0  1.0  1.0  5.0  4.0  1.0  3.0  1.0\n",
       "3  4.0  2.0  5.0  1.0  3.0  2.0  4.0  2.0  3.0  3.0\n",
       "4  3.0  1.0  3.0  2.0  2.0  3.0  5.0  3.0  4.0  3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(A.cpu().detach().numpy()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50.41853713989258\n",
      "10 48.356048583984375\n",
      "20 46.19203186035156\n",
      "30 43.69348907470703\n",
      "40 40.736228942871094\n",
      "50 37.35312271118164\n",
      "60 33.741363525390625\n",
      "70 30.15149688720703\n",
      "80 26.817447662353516\n",
      "90 23.925443649291992\n",
      "100 21.544315338134766\n",
      "110 19.651371002197266\n",
      "120 18.222267150878906\n",
      "130 17.21449089050293\n",
      "140 16.540056228637695\n",
      "150 16.09402084350586\n",
      "160 15.785305976867676\n",
      "170 15.553569793701172\n",
      "180 15.364673614501953\n",
      "190 15.19947338104248\n",
      "200 15.045867919921875\n",
      "210 14.895147323608398\n",
      "220 14.741188049316406\n",
      "230 14.580561637878418\n",
      "240 14.412769317626953\n",
      "250 14.240296363830566\n",
      "260 14.068126678466797\n",
      "270 13.90241813659668\n",
      "280 13.748640060424805\n",
      "290 13.610075950622559\n",
      "300 13.487528800964355\n",
      "310 13.380098342895508\n",
      "320 13.28618049621582\n",
      "330 13.204069137573242\n",
      "340 13.132193565368652\n",
      "350 13.0691556930542\n",
      "360 13.013742446899414\n",
      "370 12.964905738830566\n",
      "380 12.9217529296875\n",
      "390 12.88353157043457\n",
      "400 12.849600791931152\n",
      "410 12.81942081451416\n",
      "420 12.792531967163086\n",
      "430 12.768539428710938\n",
      "440 12.747105598449707\n",
      "450 12.727943420410156\n",
      "460 12.710797309875488\n",
      "470 12.695446968078613\n",
      "480 12.681700706481934\n",
      "490 12.669387817382812\n",
      "500 12.658358573913574\n",
      "510 12.648476600646973\n",
      "520 12.639623641967773\n",
      "530 12.63169002532959\n",
      "540 12.624581336975098\n",
      "550 12.618209838867188\n",
      "560 12.612496376037598\n",
      "570 12.607372283935547\n",
      "580 12.602771759033203\n",
      "590 12.598641395568848\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.Adam([W, H], lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "\n",
    "for i in range(600):\n",
    "    # Compute the loss\n",
    "    loss = torch.norm(torch.mm(W, H) - A)\n",
    "    \n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print the loss\n",
    "    if i % 10 == 0:\n",
    "        print(i, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.575108</td>\n",
       "      <td>1.702532</td>\n",
       "      <td>2.909967</td>\n",
       "      <td>1.962098</td>\n",
       "      <td>0.512695</td>\n",
       "      <td>3.499099</td>\n",
       "      <td>2.060418</td>\n",
       "      <td>0.994849</td>\n",
       "      <td>2.341826</td>\n",
       "      <td>1.372867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.551795</td>\n",
       "      <td>2.154230</td>\n",
       "      <td>3.681680</td>\n",
       "      <td>1.887276</td>\n",
       "      <td>2.698015</td>\n",
       "      <td>1.948732</td>\n",
       "      <td>3.099001</td>\n",
       "      <td>2.675164</td>\n",
       "      <td>2.812200</td>\n",
       "      <td>1.965179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  3.575108  1.702532  2.909967  1.962098  0.512695  3.499099  2.060418   \n",
       "1  2.551795  2.154230  3.681680  1.887276  2.698015  1.948732  3.099001   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.994849  2.341826  1.372867  \n",
       "1  2.675164  2.812200  1.965179  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(torch.mm(W, H).cpu().detach().numpy()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9\n",
       "0  2.0  1.0  3.0  2.0  1.0  5.0  2.0  1.0  3.0  1.0\n",
       "1  2.0  5.0  2.0  2.0  1.0  2.0  4.0  3.0  4.0  1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(A.cpu()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize(A, k, device=torch.device(\"cpu\")):\n",
    "    \"\"\"Factorize the matrix A into W and H\n",
    "    A: input matrix of size (n_users, n_movies)\n",
    "    k: number of latent features\n",
    "    \n",
    "    Returns W and H\n",
    "    W: matrix of size (n_users, k)\n",
    "    H: matrix of size (k, n_movies)\n",
    "    \"\"\"\n",
    "    A = A.to(device)\n",
    "    # Randomly initialize W and H\n",
    "    W = torch.randn(A.shape[0], k, requires_grad=True, device=device)\n",
    "    H = torch.randn(k, A.shape[1], requires_grad=True, device=device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([W, H], lr=0.01)\n",
    "    \n",
    "    # Train the model\n",
    "    for i in range(1000):\n",
    "        # Compute the loss\n",
    "        loss = torch.norm(torch.mm(W, H) - A)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    return W, H, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 17.237581253051758\n",
      "2 14.64045524597168\n",
      "3 12.626526832580566\n",
      "4 10.090561866760254\n",
      "5 8.068482398986816\n",
      "6 6.445639610290527\n",
      "9 2.5516481399536133\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 2, 3, 4, 5, 6, 9]:\n",
    "    W, H, loss = factorize(A, k, device=device)\n",
    "    print(k, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.246811</td>\n",
       "      <td>1.106579</td>\n",
       "      <td>2.772262</td>\n",
       "      <td>1.764285</td>\n",
       "      <td>1.264044</td>\n",
       "      <td>4.958205</td>\n",
       "      <td>1.843984</td>\n",
       "      <td>0.829514</td>\n",
       "      <td>3.163038</td>\n",
       "      <td>1.138836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.047336</td>\n",
       "      <td>5.023692</td>\n",
       "      <td>1.958394</td>\n",
       "      <td>1.962901</td>\n",
       "      <td>1.051947</td>\n",
       "      <td>1.987499</td>\n",
       "      <td>3.977806</td>\n",
       "      <td>2.955147</td>\n",
       "      <td>4.026937</td>\n",
       "      <td>1.025083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  2.246811  1.106579  2.772262  1.764285  1.264044  4.958205  1.843984   \n",
       "1  2.047336  5.023692  1.958394  1.962901  1.051947  1.987499  3.977806   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.829514  3.163038  1.138836  \n",
       "1  2.955147  4.026937  1.025083  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(torch.mm(W,H).cpu().detach().numpy()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9\n",
       "0  2.0  1.0  3.0  2.0  1.0  5.0  2.0  1.0  3.0  1.0\n",
       "1  2.0  5.0  2.0  2.0  1.0  2.0  4.0  3.0  4.0  1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(A.cpu()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, 5., nan, 5., 5., 4., nan, 2., nan, 5.],\n",
       "        [4., nan, 1., 5., nan, 3., 1., 4., 5., 3.],\n",
       "        [nan, 5., nan, nan, 1., nan, 4., nan, nan, 1.],\n",
       "        [nan, 5., 1., 3., 4., 5., 3., 3., nan, 2.],\n",
       "        [nan, nan, nan, nan, 1., nan, nan, nan, 1., 4.],\n",
       "        [nan, 1., nan, 5., nan, 3., 3., nan, nan, 1.],\n",
       "        [nan, 2., 1., 2., 2., nan, 5., nan, nan, 1.],\n",
       "        [nan, nan, nan, 1., nan, 4., 5., 4., nan, 3.],\n",
       "        [nan, nan, 1., nan, nan, nan, 4., 5., 5., nan],\n",
       "        [3., nan, nan, 4., 1., nan, 4., 5., 5., 3.],\n",
       "        [5., 4., nan, nan, nan, nan, 4., nan, 4., nan],\n",
       "        [1., nan, nan, 3., nan, nan, 4., 5., 4., 5.],\n",
       "        [nan, 3., nan, 5., nan, 4., nan, nan, nan, nan],\n",
       "        [nan, nan, nan, 2., 5., 4., 5., 4., 1., nan],\n",
       "        [3., 4., 2., nan, 3., 2., 1., nan, nan, 4.],\n",
       "        [nan, 5., 3., 4., 5., 5., 5., nan, 3., 1.],\n",
       "        [nan, nan, nan, 4., 5., 1., 2., nan, nan, 4.],\n",
       "        [nan, nan, 3., nan, 2., nan, nan, 1., 2., nan],\n",
       "        [2., nan, 5., 4., nan, nan, 5., 3., 3., nan],\n",
       "        [2., 2., nan, 3., nan, nan, 3., nan, 5., nan]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With missing values\n",
    "\n",
    "# Randomly replace some entries with NaN\n",
    "\n",
    "A = torch.randint(1, 6, (n_users, n_movies), dtype=torch.float)\n",
    "A[torch.rand(A.shape) < 0.5] = float('nan')\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, H, loss = factorize(A, 2, device=device)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True,  True,  True, False,  True, False,  True],\n",
       "        [ True, False,  True,  True, False,  True,  True,  True,  True,  True],\n",
       "        [False,  True, False, False,  True, False,  True, False, False,  True],\n",
       "        [False,  True,  True,  True,  True,  True,  True,  True, False,  True],\n",
       "        [False, False, False, False,  True, False, False, False,  True,  True],\n",
       "        [False,  True, False,  True, False,  True,  True, False, False,  True],\n",
       "        [False,  True,  True,  True,  True, False,  True, False, False,  True],\n",
       "        [False, False, False,  True, False,  True,  True,  True, False,  True],\n",
       "        [False, False,  True, False, False, False,  True,  True,  True, False],\n",
       "        [ True, False, False,  True,  True, False,  True,  True,  True,  True],\n",
       "        [ True,  True, False, False, False, False,  True, False,  True, False],\n",
       "        [ True, False, False,  True, False, False,  True,  True,  True,  True],\n",
       "        [False,  True, False,  True, False,  True, False, False, False, False],\n",
       "        [False, False, False,  True,  True,  True,  True,  True,  True, False],\n",
       "        [ True,  True,  True, False,  True,  True,  True, False, False,  True],\n",
       "        [False,  True,  True,  True,  True,  True,  True, False,  True,  True],\n",
       "        [False, False, False,  True,  True,  True,  True, False, False,  True],\n",
       "        [False, False,  True, False,  True, False, False,  True,  True, False],\n",
       "        [ True, False,  True,  True, False, False,  True,  True,  True, False],\n",
       "        [ True,  True, False,  True, False, False,  True, False,  True, False]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = ~torch.isnan(A)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(110)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn(A.shape[0], k, requires_grad=True, device=device)\n",
    "H = torch.randn(k, A.shape[1],  requires_grad=True, device=device)\n",
    "\n",
    "diff_matrix = torch.mm(W, H)-A.to(device)\n",
    "diff_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     nan,  -7.8159,      nan,  -9.2992,  -2.0465,  -3.0997,      nan,\n",
       "          -3.7238,      nan,  -0.3907],\n",
       "        [ -4.9107,      nan,   1.1464,  -7.3782,      nan,  -2.9703,  -6.8321,\n",
       "          -4.4837,  -5.0601,  -4.0388],\n",
       "        [     nan,  -5.6427,      nan,      nan,   0.4110,      nan,  -1.2884,\n",
       "              nan,      nan,  -3.2478],\n",
       "        [     nan,  -6.7050,  -1.3138,  -4.4632,  -2.2068,  -5.2276,  -1.3345,\n",
       "          -6.3128,      nan,   1.6927],\n",
       "        [     nan,      nan,      nan,      nan,  -2.9860,      nan,      nan,\n",
       "              nan,  -0.7004,  -4.3378],\n",
       "        [     nan,   0.6152,      nan,  -3.9136,      nan,  -4.0817,   0.2097,\n",
       "              nan,      nan,  -2.7844],\n",
       "        [     nan,   0.8705,  -3.6554,   2.8964,  -2.2121,      nan,  -5.0491,\n",
       "              nan,      nan,  -0.3602],\n",
       "        [     nan,      nan,      nan,  -0.4069,      nan,  -6.1057,  -4.9046,\n",
       "          -2.6270,      nan,  -0.1867],\n",
       "        [     nan,      nan,  -0.5713,      nan,      nan,      nan,   3.5492,\n",
       "          -1.6805,  -4.9921,      nan],\n",
       "        [ -1.7382,      nan,      nan,  -0.3238,  -1.2536,      nan,  -4.4641,\n",
       "         -10.0167,  -5.6237,  -2.5126],\n",
       "        [ -3.0747,  -9.0374,      nan,      nan,      nan,      nan,  -0.8869,\n",
       "              nan,  -6.9920,      nan],\n",
       "        [ -0.6748,      nan,      nan,  -2.9581,      nan,      nan,  -0.9878,\n",
       "          -6.8892,  -9.1066,  -6.5258],\n",
       "        [     nan,  -5.8057,      nan,  -3.0527,      nan,  -3.7564,      nan,\n",
       "              nan,      nan,      nan],\n",
       "        [     nan,      nan,      nan,  -0.2103,  -4.2219,  -5.9887,  -3.3150,\n",
       "          -6.5657,  -4.0257,      nan],\n",
       "        [ -2.7402,  -1.5698,  -4.1995,      nan,  -3.3560,  -4.9832,  -1.1865,\n",
       "              nan,      nan,  -1.1490],\n",
       "        [     nan,  -4.9712,  -1.5971,  -5.5522,  -7.0491,  -4.1803,  -4.6709,\n",
       "              nan,  -2.7057,  -3.2016],\n",
       "        [     nan,      nan,      nan,  -5.0673,  -8.9810,  -0.0310,  -2.0630,\n",
       "              nan,      nan,  -2.6412],\n",
       "        [     nan,      nan,  -5.2339,      nan,  -4.2858,      nan,      nan,\n",
       "          -0.6259,   1.3348,      nan],\n",
       "        [ -2.3342,      nan,  -4.4320,  -4.0071,      nan,      nan,  -9.1008,\n",
       "          -3.8505,  -0.0944,      nan],\n",
       "        [ -3.5569,  -8.6446,      nan,  -8.0847,      nan,      nan,  -3.7245,\n",
       "              nan,  -8.8381,      nan]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([110])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_matrix[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the loss function to ignore NaN values\n",
    "\n",
    "def factorize(A, k, device=torch.device(\"cpu\")):\n",
    "    \"\"\"Factorize the matrix D into A and B\"\"\"\n",
    "    A = A.to(device)\n",
    "    # Randomly initialize A and B\n",
    "    W = torch.randn(A.shape[0], k, requires_grad=True, device=device)\n",
    "    H = torch.randn(k, A.shape[1], requires_grad=True, device=device)\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([W, H], lr=0.01)\n",
    "    mask = ~torch.isnan(A)\n",
    "    # Train the model\n",
    "    for i in range(1000):\n",
    "        # Compute the loss\n",
    "        diff_matrix = torch.mm(W, H) - A\n",
    "        diff_vector = diff_matrix[mask]\n",
    "        loss = torch.norm(diff_vector)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    return W, H, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9144, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W, H, loss = factorize(A, 5, device=device)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2.5415,   5.0024,  18.7974,   5.0142,   4.9969,   3.9942,   9.7405,\n",
       "           2.0035,   0.8238,   4.9845],\n",
       "        [  4.0599,   6.7069,   0.9981,   4.9338,   8.0675,   3.0101,   0.9941,\n",
       "           4.0033,   4.9817,   3.0420],\n",
       "        [  6.7136,   5.0008, -15.3943,   5.3809,   0.9999,   6.1654,   3.9998,\n",
       "          -4.1563,   6.7969,   1.0010],\n",
       "        [  3.3376,   4.8514,   1.0618,   3.4958,   3.9746,   4.9690,   2.9209,\n",
       "           3.0104,   4.5712,   1.6154],\n",
       "        [  4.0478,   1.0344, -15.9771,   4.9748,   1.0000,  -5.9608,  -1.8545,\n",
       "          -7.5956,   1.0004,   3.9999],\n",
       "        [  6.7118,   1.0085, -26.4594,   4.9814,  -5.9511,   2.9992,   3.0036,\n",
       "          -9.6801,   5.7766,   1.0123],\n",
       "        [  2.1379,   1.9227,   1.0254,   2.1982,   1.9975,   1.2639,   4.9633,\n",
       "          -5.3452,  -0.7114,   0.8575],\n",
       "        [  0.2025,  -5.4665,  -1.9851,   0.9977, -17.1253,   4.0034,   4.9972,\n",
       "           3.9981,   4.3034,   3.0048],\n",
       "        [  1.5030,   0.5447,   0.9971,   1.2707,  -5.2621,   6.8088,   4.0055,\n",
       "           5.0067,   4.9907,   0.7143],\n",
       "        [  2.9946,   3.7835,   3.9530,   3.9136,   1.0141,   5.0678,   4.0076,\n",
       "           4.9785,   5.0446,   3.0615],\n",
       "        [  4.9945,   4.0027, -16.2711,   1.4554,   1.7743,   7.9855,   4.0006,\n",
       "          -7.9111,   4.0016,  -4.1173],\n",
       "        [  1.0287,  -2.3773,   2.2070,   2.9907, -10.2492,   1.8415,   3.9985,\n",
       "           5.0081,   3.9839,   4.9996],\n",
       "        [  3.2884,   3.0003,   6.6151,   5.0003,  -0.6491,   3.9998,   7.0419,\n",
       "           2.1403,   3.5961,   4.6992],\n",
       "        [  0.9113,   3.9388,  14.0529,   2.0075,   4.9988,   4.0055,   4.9948,\n",
       "           4.0003,   0.9932,   1.7733],\n",
       "        [  2.9309,   4.0265,   1.9850,   4.4090,   3.0023,   2.0047,   1.0167,\n",
       "           5.4324,   4.7815,   4.0225],\n",
       "        [  3.5244,   5.1411,   2.9428,   3.5816,   5.0165,   5.0198,   5.0740,\n",
       "          -0.0988,   2.9875,   1.3196],\n",
       "        [  2.1776,   4.1694,   7.1359,   4.0039,   4.9996,   0.9977,   2.0017,\n",
       "           4.2597,   2.5932,   3.9947],\n",
       "        [  3.2400,   2.6132,   2.9948,   6.6213,   1.9976,  -3.6964,   2.1492,\n",
       "           1.0003,   2.0016,   7.7609],\n",
       "        [  1.9904,   0.4912,   5.0003,   4.0032,  -4.1358,   1.7867,   4.9982,\n",
       "           2.9951,   3.0083,   4.9788],\n",
       "        [  2.0005,   2.0002,   3.5329,   3.0006,  -1.9555,   4.4708,   2.9998,\n",
       "           6.3002,   4.9994,   2.9984]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.541451</td>\n",
       "      <td>5.002381</td>\n",
       "      <td>18.797421</td>\n",
       "      <td>5.014181</td>\n",
       "      <td>4.996908</td>\n",
       "      <td>3.994238</td>\n",
       "      <td>9.740495</td>\n",
       "      <td>2.003469</td>\n",
       "      <td>0.823797</td>\n",
       "      <td>4.984483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.059857</td>\n",
       "      <td>6.706933</td>\n",
       "      <td>0.998094</td>\n",
       "      <td>4.933802</td>\n",
       "      <td>8.067493</td>\n",
       "      <td>3.010138</td>\n",
       "      <td>0.994078</td>\n",
       "      <td>4.003255</td>\n",
       "      <td>4.981701</td>\n",
       "      <td>3.042045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2         3         4         5         6  \\\n",
       "0  2.541451  5.002381  18.797421  5.014181  4.996908  3.994238  9.740495   \n",
       "1  4.059857  6.706933   0.998094  4.933802  8.067493  3.010138  0.994078   \n",
       "\n",
       "          7         8         9  \n",
       "0  2.003469  0.823797  4.984483  \n",
       "1  4.003255  4.981701  3.042045  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(torch.mm(W,H).cpu().detach().numpy()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9\n",
       "0  NaN  5.0  NaN  5.0  5.0  4.0  NaN  2.0  NaN  5.0\n",
       "1  4.0  NaN  1.0  5.0  NaN  3.0  1.0  4.0  5.0  3.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(A.cpu()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
